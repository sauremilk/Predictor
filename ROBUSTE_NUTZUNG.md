# üîß Robuste Wege zur Modell-Nutzung (ohne Web-Interface)

## √úbersicht der Methoden

| Methode | Use Case | Robustheit | Performance |
|---------|----------|------------|-------------|
| **1. Direkte Python-Integration** | Integration in eigene Python-Apps | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° Sehr schnell |
| **2. Batch-Processing (CSV)** | Viele Predictions auf einmal | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° Sehr schnell |
| **3. CLI-Tool** | Scripts, Automation, CI/CD | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° Schnell |
| **4. REST API** | Microservices, Web-Apps | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° Netzwerk-Overhead |

---

## 1. Direkte Python-Integration ‚≠ê EMPFOHLEN

**Wann nutzen:** Du entwickelst in Python und brauchst maximale Performance.

**Datei:** `direct_prediction.py`

```bash
python3 direct_prediction.py
```

**Vorteile:**
- ‚úÖ Kein Server/Netzwerk n√∂tig
- ‚úÖ Maximale Performance (< 1ms pro Prediction)
- ‚úÖ Einfach in eigenen Code zu integrieren
- ‚úÖ Vollst√§ndige Kontrolle

**Integration in deinen Code:**
```python
import joblib
import pandas as pd

# Modell einmal laden
pipeline = joblib.load("Vorhersage-Modell/models/baseline_pipeline_final.joblib")

# Prediction
game_state = {"zone_phase": "mid", "alive_players": 30, ...}
df = pd.DataFrame([game_state])
prediction = pipeline.predict(df)[0]
```

---

## 2. Batch-Processing (CSV/JSONL) ‚≠ê F√úR GROSSE DATENMENGEN

**Wann nutzen:** Du hast viele Game States (100+) und willst sie alle auf einmal verarbeiten.

**Datei:** `batch_predict.py`

```bash
python3 batch_predict.py
```

**Anpassung f√ºr eigene Daten:**
```python
# In batch_predict.py √§ndern:
input_file = "meine_daten.csv"
output_file = "ergebnisse.csv"
```

**Vorteile:**
- ‚úÖ Sehr effizient f√ºr gro√üe Datenmengen
- ‚úÖ Einfacher CSV-Workflow
- ‚úÖ Ergebnisse direkt als CSV (Excel-kompatibel)
- ‚úÖ Vektorisierte Operationen (schnell)

**Performance:** ~1000 Predictions in < 1 Sekunde

---

## 3. CLI-Tool ‚≠ê F√úR AUTOMATION

**Wann nutzen:** Scripts, Shell-Integration, CI/CD-Pipelines.

**Datei:** `predict_cli.py`

### Beispiele:

**Single Prediction (Text-Output):**
```bash
./predict_cli.py \
  --zone late \
  --players 15 \
  --team 2 \
  --height low \
  --position corner
```

**JSON-Output (f√ºr weitere Verarbeitung):**
```bash
./predict_cli.py \
  --zone mid \
  --players 20 \
  --team 3 \
  --height mid \
  --position edge \
  --format json
```

**Quiet Mode (nur Call, f√ºr Scripts):**
```bash
CALL=$(./predict_cli.py --zone late --players 10 --team 2 --height low --position corner --quiet)
echo "Recommended: $CALL"
```

**JSON-Input:**
```bash
./predict_cli.py --json '{"zone_phase": "mid", "alive_players": 30, "teammates_alive": 3, "height_status": "mid", "position_type": "edge", "storm_edge_dist": 100, "mats_total": 300, "surge_above": 10, "zone_index": 5}'
```

**Batch CSV-Processing:**
```bash
./predict_cli.py --csv input.csv --output predictions.csv
```

**Vorteile:**
- ‚úÖ Shell-Integration
- ‚úÖ Flexible Output-Formate (text/json/quiet)
- ‚úÖ Perfekt f√ºr Automation
- ‚úÖ Keine Python-Kenntnisse n√∂tig (einmal setup, dann CLI)

**Hilfe anzeigen:**
```bash
./predict_cli.py --help
```

---

## 4. REST API (bereits vorhanden)

**Wann nutzen:** Microservices, Web-Apps, externe Systeme.

**Server starten:**
```bash
cd Vorhersage-Modell
./manage_api.sh start
```

**Nutzung:**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"zone_phase": "mid", "alive_players": 30, ...}'
```

**Vorteile:**
- ‚úÖ Sprachunabh√§ngig (jede Sprache kann HTTP)
- ‚úÖ Ideal f√ºr verteilte Systeme
- ‚úÖ Swagger-Dokumentation unter `/docs`

**Nachteile:**
- ‚ùå Netzwerk-Overhead (~10-50ms)
- ‚ùå Server muss laufen

---

## Performance-Vergleich

| Methode | Latency (Single) | Throughput (Batch) |
|---------|------------------|-------------------|
| Direkte Integration | < 1ms | 10,000+/sec |
| Batch CSV | N/A | 5,000+/sec |
| CLI-Tool | ~50ms (Startup) | 500/sec |
| REST API | 10-50ms | 100-500/sec |

---

## Empfehlung nach Use Case

### üéØ **Du entwickelst eine Python-App**
‚Üí **Direkte Integration** (`direct_prediction.py`)
- Einfachste Integration
- Beste Performance
- Keine Dependencies

### üìä **Du hast gro√üe Datasets zum Analysieren**
‚Üí **Batch-Processing** (`batch_predict.py`)
- CSV rein, CSV raus
- Sehr schnell
- Excel-kompatibel

### ‚öôÔ∏è **Du brauchst es in Shell-Scripts/Automation**
‚Üí **CLI-Tool** (`predict_cli.py`)
- Flexible Nutzung
- Quiet-Mode f√ºr Scripts
- JSON-Support

### üåê **Du willst es von anderen Sprachen/Services nutzen**
‚Üí **REST API** (`api_server.py`)
- HTTP-basiert
- Sprachunabh√§ngig
- Swagger-Docs

---

## Quick Start

Alle Tools sind fertig, teste sie einfach:

```bash
cd /workspaces/Predictor

# 1. Direkte Python-Nutzung
python3 direct_prediction.py

# 2. Batch-Processing (nutzt Demo-Daten)
python3 batch_predict.py

# 3. CLI-Tool
./predict_cli.py --zone late --players 15 --team 2 --height low --position corner

# 4. REST API (bereits l√§uft)
curl http://localhost:8000/health
```

---

## Anpassung f√ºr deine Daten

### Eigene CSV verarbeiten:
```python
# In batch_predict.py:
input_file = "pfad/zu/deinen/daten.csv"
output_file = "pfad/zu/ergebnissen.csv"
```

### In eigenen Code integrieren:
```python
# Kopiere aus direct_prediction.py und passe an
import joblib
pipeline = joblib.load("Vorhersage-Modell/models/baseline_pipeline_final.joblib")
# ... deine Logik
```

### CLI in Scripts nutzen:
```bash
#!/bin/bash
CALL=$(./predict_cli.py --zone mid --players 20 --team 3 --height mid --position edge --quiet)
echo "AI recommends: $CALL"
```

---

## Troubleshooting

**"Pipeline not found"**
- Pr√ºfe Pfad: `ls -la Vorhersage-Modell/models/baseline_pipeline_final.joblib`
- Stelle sicher, du bist im Root-Verzeichnis: `cd /workspaces/Predictor`

**"Missing columns"**
- Stelle sicher, alle Features sind gesetzt (inkl. `outcome_placement`, `outcome_alive_time`)
- Check Schema in `direct_prediction.py`

**Performance-Probleme**
- Nutze Batch-Processing statt einzelne Predictions
- Lade Modell nur einmal (nicht pro Prediction)

---

**Welche Methode passt f√ºr deinen Use Case?**
